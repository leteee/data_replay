# 项目核心准则
1.  **一切皆遵循最佳实践 (Best Practices as Foundation)**: 这是项目的基石准则。从顶层架构设计到底层代码实现的每一个细节，从开发工作流到依赖管理，所有方面都**必须**严格对齐业界公认的、当前主流的最佳实践，不存在任何妥协。
2.  **高度模块化与灵活性 (High Modularity & Flexibility)**: 框架的核心是可插拔、松耦合的插件化架构。所有组件都应独立解耦，确保系统拥有强大的灵活性和可扩展性。
3.  **分层可覆盖的配置体系 (Layered, Overridable Configuration)**: 框架采用统一的、分优先级的配置管理。除日志系统外，所有配置的加载优先级顺序为：**命令行参数 > Case 配置 > 全局配置 > 插件默认配置**。高优先级配置会覆盖低优先级配置，确保运行时的精确控制。

# 项目核心功能与机制 (代码级分析)

**I. 执行核心 (Execution Core)**

*   **1. 流水线协调器 (`PipelineRunner`)**:
    *   **机制**: 作为核心引擎，它严格按照 `case.yaml` 中 `pipeline` 数组定义的顺序，依次实例化并执行每个插件。
    *   **要求**: 负责在每个插件执行前后，维护 `DataHub` 的状态，确保数据在插件间正确流动。

*   **2. 插件独立运行器 (`plugin_helper`)**:
    *   **机制**: 提供 `run_plugin_standalone` 和 `run_single_plugin_by_name` 功能，允许任何插件脱离完整的 `pipeline`，作为一个独立的脚本直接运行。
    *   **要求**: 独立运行时，它会模拟 `pipeline` 环境，自动加载全局配置、案例配置，并初始化 `DataHub`，这对于插件的独立开发和调试至关重要。

**II. 配置处理核心 (Configuration Core)**

*   **1. 分层配置管理器 (`ConfigManager`)**:
    *   **机制**: 负责从文件系统加载 `global.yaml` 和 `case.yaml`。
    *   **要求**: 它的核心职责是解析路径（如 `project_root`, `cases_root`）并为其他模块提供统一的配置访问接口。

*   **2. 插件配置处理器 (`PluginConfigProcessor`)**:
    *   **机制**: 这是连接 `ConfigManager` 和单个插件的桥梁。它在插件运行前，专门负责准备该插件的最终配置。
    *   **要求**:
        *   **配置合并**: 必须严格按照 **Case > Global > 插件默认** 的优先级，将 `case.yaml` 中的参数覆盖到插件的默认 `.yaml` 配置上。
        *   **动态变量替换**: 必须自动替换配置值中的动态变量，例如将字符串 `{case_path}` 替换为实际的案例路径，实现配置的动态化。

**III. 数据核心 (Data Core)**

*   **1. 集中式数据总线 (`DataHub`)**:
    *   **机制**: 它是一个贯穿整个 `pipeline` 生命周期的单例服务。其内部通过字典来持有数据对象，扮演着“数据状态管理器”的角色。
    *   **要求**:
        *   **统一访问**: 为所有插件提供 `get_data()` 和 `add_data()` 方法，作为数据存取的唯一入口。
        *   **数据隔离**: 插件不直接互相通信，所有数据交换必须通过 `DataHub` 进行，以实现解耦。

*   **2. 可扩展数据处理器 (`Handlers`)**:
    *   **机制**: `DataHub` 的一项关键能力。它通过一个 `handlers` 注册表，将数据的“标识符”与具体的“读/写逻辑”分离。
    *   **要求**:
        *   **接口统一**: 所有 `Handler`（如 `CsvHandler`, `JsonHandler`）都必须实现共同的 `read()` 和 `write()` 接口。
        *   **懒加载**: `DataHub` 在被请求获取某个数据时，会根据其在 `data_sources` 配置中的类型，选择合适的 `Handler` 进行实时的文件读取。

**IV. 插件子系统 (Plugin Subsystem)**

*   **1. 插件基类 (`BasePlugin`)**:
    *   **机制**: 一个极其轻量的基类，仅定义了插件必须实现的 `__init__(self, config)` 和 `run(self, data_hub)` 两个核心方法。
    *   **要求**: 插件的开发体验必须简单：继承基类，实现 `run` 方法，然后提供一个默认的 `.yaml` 配置文件。

*   **2. 插件自动发现与文档生成**:
    *   **机制**: 通过 `pkgutil` 和 `inspect` 标准库，在程序启动时或执行 `generate-docs` 命令时，动态地扫描 `plugins` 包。
    *   **要求**:
        *   **自动注册**: 无需任何手动注册，只要放在 `plugins` 目录下的 `BasePlugin` 子类就能被框架找到并使用。
        *   **自动文档**: `generate-docs` 脚本必须能利用此机制，自动提取插件的文档字符串及其默认 `.yaml` 配置，生成 `PLUGINS.md` 文件。

**V. 项目工具与质量保证 (Tooling & QA)**

*   **1. 端到端测试 (`e2e_test.py`)**:
    *   **机制**: 一个独立的测试脚本，通过实际运行一个预设的 `demo` 案例，并断言最终输出结果是否符合预期。
    *   **要求**: 它是保证所有核心机制（从配置加载到插件执行再到数据处理）正确协同工作的最终防线。

*   **2. 案例模板化**:
    *   **机制**: `run.py` 中的 `pipeline` 命令通过 `shutil.copy` 实现。
    *   **要求**: 提供一种快速引导新案例的方法，确保新案例具有标准化的目录结构和配置文件。

---

# 工作状态记录

## 指令格式（用于未来）
当您需要我记录当前工作状态时，请使用以下格式：
`# 指令：记录工作状态\n\n**任务**: <填写任务目标>\n**计划**: <填写为完成任务需要执行的步骤>\n**进展**: <填写当前进展到哪一步了>`

---

## 当前工作记录 (2025-09-02)

**任务**: 遵循“最高准则”，重构核心执行逻辑。
*   **目标**: 消除代码重复，明确模块职责，使代码更健壮、更易于维护。

**计划**:
1.  **引入 `ExecutionContext`**: 创建一个新类，集中管理运行环境的搭建（配置、数据总线、日志）。
2.  **引入 `PluginExecutor`**: 创建一个新类，专门负责在给定的上下文中执行单个插件。
3.  **重构 `PipelineRunner`**: 使其依赖 `ExecutionContext` 和 `PluginExecutor`，简化自身逻辑。
4.  **重构 `plugin_helper`**: 移除其内部重复的环境搭建代码，使其同样依赖新模块。
5.  **调试与验证**: 修复重构后出现的所有错误，直到端到端测试 (`e2e_test.py`) 完全通过。

**进展**:
*   步骤 1-4 已全部完成。
*   我们正处于步骤 5 的最后阶段。在测试中发现了一系列错误（`ImportError`, `AttributeError` 等），并已逐一修复。
*   当前状态：刚刚修复了 `DataHub` 中的一个 `AttributeError` (`_data_sources` 拼写错误)。**下一步是再次运行 `e2e_test.py` 来最终验证所有修复**。