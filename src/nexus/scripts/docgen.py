from nexus.core.plugin.decorator import PLUGIN_REGISTRY
from nexus.core.plugin.discovery import discover_plugins
from nexus.core.data.handlers import get_handler
from nexus.core.data.handlers.decorator import HANDLER_REGISTRY
from nexus.core.data.handlers.discovery import discover_handlers
from nexus.core.data.hub import DataHub
from nexus.core.context import PluginContext
from logging import Logger
from pydantic import BaseModel
import inspect
import yaml
from pathlib import Path
from typing import get_type_hints, get_args, get_origin, Annotated, Union
import pandas as pd
import numpy as np


def _get_default_config(plugin_spec) -> dict:
    """Safely loads the default YAML config for a plugin."""
    try:
        plugin_module = inspect.getmodule(plugin_spec.func)
        if plugin_module and plugin_module.__file__:
            yaml_path = Path(plugin_module.__file__).with_suffix('.yaml')
            if yaml_path.exists():
                with open(yaml_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f) or {}
    except Exception:
        return {}
    return {}


def _format_value(value):
    """Formats default values for display in Markdown."""
    if isinstance(value, str) and not value:
        return '""'
    if isinstance(value, list) and not value:
        return '[]'
    if isinstance(value, dict) and not value:
        return '{}'
    return f'`{value}`'


def _get_type_name(annotation):
    """Get a readable name for a type annotation."""
    if hasattr(annotation, '__name__'):
        return annotation.__name__
    elif hasattr(annotation, '_name'):
        return annotation._name
    else:
        return str(annotation).replace('typing.', '')


def generate_plugin_documentation():
    """
    Finds all plugins and handlers, extracts their info, and writes PLUGINS.md.
    This refactored version uses the decorator registries for discovery.
    """
    project_root = Path(__file__).resolve().parent.parent.parent.parent
    output_file = project_root / 'REFERENCE.md'
    
    # 1. Discover everything
    import logging
    logger = logging.getLogger(__name__)
    
    global_config_path = project_root / "config" / "global.yaml"
    with open(global_config_path, 'r', encoding='utf-8') as f:
        global_config = yaml.safe_load(f)
    
    plugin_modules = global_config.get("plugin_modules", [])
    discover_plugins(plugin_modules, logger)
    discover_handlers(logger)

    # 2. Process Plugins
    md_content = """# Framework Reference

This document provides a reference for all available Plugins and Data Handlers in the framework.
It is auto-generated by `data-replay docs`. Do not edit it manually.

---

"""
    
    md_content += "## Plugins\n\n"
    
    sorted_plugins = sorted(PLUGIN_REGISTRY.values(), key=lambda p: p.name)
    
    for spec in sorted_plugins:
        md_content += f"### {spec.name}\n\n"
        
        docstring = inspect.getdoc(spec.func)
        md_content += f"{docstring}\n\n" if docstring else "No description provided.\n\n"

        params = inspect.signature(spec.func).parameters
        default_config = _get_default_config(spec)
        
        # Injected Dependencies
        injected_params = [p for p in params.values() if p.annotation in [DataHub, Logger, Path, PluginContext]]
        if injected_params:
            md_content += "**Core Dependencies Injected:**\n"
            md_content += ", ".join([f'`{p.annotation.__name__}`' for p in injected_params])
            md_content += "\n\n"

        # Check for PluginContext parameter which contains the Pydantic config
        plugin_context_params = [p for p in params.values() if p.annotation == PluginContext]
        if plugin_context_params and spec.config_model:
            # Extract I/O annotations from the config model in the PluginContext
            model = spec.config_model
            md_content += "**Configuration Parameters (from Pydantic Model):**\n\n"
            md_content += "| Name | Type | Default | Description |\n"
            md_content += "|------|------|---------|-------------|\n"
            for field_name, field in model.model_fields.items():
                default_val = _format_value(field.default)
                description = field.description or ''
                md_content += f"| `{field_name}` | `{_get_type_name(field.annotation)}` | {default_val} | {description} |\n"
            md_content += "\n"
            
            # Extract I/O annotations using model fields directly
            data_sources = []
            data_sinks = []
            
            for field_name, field in model.model_fields.items():
                # Check field metadata for DataSource and DataSink annotations
                if hasattr(field, 'metadata'):
                    for item in field.metadata:
                        if hasattr(item, '__class__') and hasattr(item, 'name'):
                            if item.__class__.__name__ == 'DataSource':
                                data_sources.append({
                                    'name': field_name,
                                    'logical_name': getattr(item, 'name', ''),
                                    'type': _get_type_name(field.annotation),
                                    'handler_args': getattr(item, 'handler_args', {})
                                })
                            elif item.__class__.__name__ == 'DataSink':
                                data_sinks.append({
                                    'name': field_name,
                                    'logical_name': getattr(item, 'name', ''),
                                    'type': _get_type_name(field.annotation),
                                    'handler_args': getattr(item, 'handler_args', {})
                                })
            
            if data_sources:
                md_content += "**Data Sources:**\n\n"
                md_content += "| Field Name | Logical Name | Type | Description |\n"
                md_content += "|------------|--------------|------|-------------|\n"
                for source in data_sources:
                    md_content += f"| `{source['name']}` | `{source['logical_name']}` | `{source['type']}` | Data input source |\n"
                md_content += "\n"
                
            if data_sinks:
                md_content += "**Data Sinks:**\n\n"
                md_content += "| Field Name | Logical Name | Type | Description |\n"
                md_content += "|------------|--------------|------|-------------|\n"
                for sink in data_sinks:
                    md_content += f"| `{sink['name']}` | `{sink['logical_name']}` | `{sink['type']}` | Data output destination |\n"
                md_content += "\n"
        else:
            # Fallback to simple config parameters if no PluginContext or config model
            config_params = [p for p in params.values() if p.annotation not in [DataHub, Logger, Path, PluginContext]]
            if config_params:
                md_content += "**Configuration Parameters:**\n\n"
                md_content += "| Name | Default Value (from .yaml) |\n"
                md_content += "|------|----------------------------|\n"
                for p in config_params:
                    default_val = _format_value(default_config.get(p.name, 'N/A'))
                    md_content += f"| `{p.name}` | {default_val} |\n"
                md_content += "\n"


    # 3. Process Handlers
    md_content += "---\n## Data Handlers\n\n"
    md_content += "Data Handlers are responsible for reading and writing different data formats.\n\n"
    md_content += "| Name | Supported Extensions | Description |\n"
    md_content += "|------|----------------------|-------------|\n"

    # Process registry to be one line per handler class
    processed_handlers = {}
    for key, handler_cls in HANDLER_REGISTRY.items():
        if handler_cls not in processed_handlers:
            processed_handlers[handler_cls] = {'name': 'N/A', 'extensions': []}
        
        if key.startswith('.'):
            processed_handlers[handler_cls]['extensions'].append(f'`{key}`')
        else:
            processed_handlers[handler_cls]['name'] = f'`{key}`'

    sorted_handlers = sorted(processed_handlers.items(), key=lambda item: item[1]['name'])

    for handler_cls, info in sorted_handlers:
        docstring = inspect.getdoc(handler_cls) or ""
        description = docstring.split('\n')[0] # First line of docstring
        extensions_str = ", ".join(sorted(info['extensions'])) or 'N/A'
        md_content += f"| {info['name']} | {extensions_str} | {description} |\n"

    # 4. Write file
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(md_content)

    print(f"Successfully generated framework reference at {output_file}")